{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a9c38fd-ddff-46dc-8b4c-af5551b6b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybaseball in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.2.7)\n",
      "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (4.13.4)\n",
      "Requirement already satisfied: requests>=2.18.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (2.32.3)\n",
      "Requirement already satisfied: lxml>=4.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (5.2.1)\n",
      "Requirement already satisfied: pyarrow>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (16.1.0)\n",
      "Requirement already satisfied: pygithub>=1.51 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (2.6.1)\n",
      "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (1.13.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (3.9.2)\n",
      "Requirement already satisfied: tqdm>=4.50.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (4.66.5)\n",
      "Requirement already satisfied: attrs>=20.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pybaseball) (23.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.0->pybaseball) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.0->pybaseball) (4.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->pybaseball) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->pybaseball) (2023.3)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (1.5.0)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->pygithub>=1.51->pybaseball) (2.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (2.2.3)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (1.2.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tqdm>=4.50.0->pybaseball) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->pygithub>=1.51->pybaseball) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.4.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pynacl>=1.4.0->pygithub>=1.51->pybaseball) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pybaseball) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from Deprecated->pygithub>=1.51->pybaseball) (1.14.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alex\\anaconda3\\lib\\site-packages (from cffi>=1.4.1->pynacl>=1.4.0->pygithub>=1.51->pybaseball) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pybaseball\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abb5182d-16bb-4a8b-9f47-dbd0c2795768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Total monthly chunks: 29\n"
     ]
    }
   ],
   "source": [
    "from pybaseball import statcast\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set monthly date ranges from Jan 2023 to May 2025\n",
    "def generate_monthly_date_ranges(start_date: str, end_date: str):\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    ranges = []\n",
    "    while start < end:\n",
    "        month_end = (start + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "        if month_end > end:\n",
    "            month_end = end\n",
    "        ranges.append((start.strftime(\"%Y-%m-%d\"), month_end.strftime(\"%Y-%m-%d\")))\n",
    "        start = month_end + timedelta(days=1)\n",
    "    return ranges\n",
    "\n",
    "date_ranges = generate_monthly_date_ranges(\"2023-01-01\", \"2025-05-31\")\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(f\"Total monthly chunks: {len(date_ranges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ed5f463-d1b6-48fd-9565-dd853d05ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define year ranges\n",
    "years = [2023, 2024]\n",
    "current_year = 2025\n",
    "\n",
    "# We're only including data up to May 31, 2025\n",
    "start_date_2025 = \"2025-04-01\"\n",
    "end_date_2025 = \"2025-05-31\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "481ca2f4-b5f5-4722-9918-0aa65f3af1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-01-01 to 2023-01-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-02-01 to 2023-02-28\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [00:02<00:00,  9.33it/s]C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\datahelpers\\postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
      "100%|██████████| 17/17 [00:07<00:00,  2.21it/s]\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-03-01 to 2023-03-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-04-01 to 2023-04-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-05-01 to 2023-05-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-06-01 to 2023-06-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:02<00:00, 10.70it/s]\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-07-01 to 2023-07-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:02<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-08-01 to 2023-08-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-09-01 to 2023-09-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-10-01 to 2023-10-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-11-01 to 2023-11-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2023-12-01 to 2023-12-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-01-01 to 2024-01-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-02-01 to 2024-02-29\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00,  8.55it/s]\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-03-01 to 2024-03-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-04-01 to 2024-04-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-05-01 to 2024-05-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:02<00:00, 10.39it/s]C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\datahelpers\\postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
      "100%|██████████| 30/30 [00:03<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-06-01 to 2024-06-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:02<00:00, 10.34it/s]\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-07-01 to 2024-07-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-08-01 to 2024-08-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-09-01 to 2024-09-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-10-01 to 2024-10-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-11-01 to 2024-11-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2024-12-01 to 2024-12-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2025-01-01 to 2025-01-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2025-02-01 to 2025-02-28\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [00:01<00:00, 13.32it/s]C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\datahelpers\\postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\datahelpers\\postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
      "100%|██████████| 17/17 [00:03<00:00,  4.44it/s]\n",
      "C:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2025-03-01 to 2025-03-31\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2025-04-01 to 2025-04-30\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: 2025-05-01 to 2025-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_30564\\185683608.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  statcast_data = pd.concat(all_data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Shape of statcast_data: (1829923, 118)\n",
      "Preview of columns:\n",
      "['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'player_name', 'batter', 'pitcher', 'events', 'description', 'spin_dir', 'spin_rate_deprecated', 'break_angle_deprecated', 'break_length_deprecated', 'zone', 'des', 'game_type', 'stand', 'p_throws', 'home_team', 'away_team', 'type', 'hit_location', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', 'hc_x', 'hc_y', 'tfs_deprecated', 'tfs_zulu_deprecated', 'umpire', 'sv_id', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'game_pk', 'fielder_2', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'babip_value', 'iso_value', 'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name', 'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score', 'post_home_score', 'post_bat_score', 'post_fld_score', 'if_fielding_alignment', 'of_fielding_alignment', 'spin_axis', 'delta_home_win_exp', 'delta_run_exp', 'bat_speed', 'swing_length', 'estimated_slg_using_speedangle', 'delta_pitcher_run_exp', 'hyper_speed', 'home_score_diff', 'bat_score_diff', 'home_win_exp', 'bat_win_exp', 'age_pit_legacy', 'age_bat_legacy', 'age_pit', 'age_bat', 'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat', 'pitcher_days_since_prev_game', 'batter_days_since_prev_game', 'pitcher_days_until_next_game', 'batter_days_until_next_game', 'api_break_z_with_gravity', 'api_break_x_arm', 'api_break_x_batter_in', 'arm_angle', 'attack_angle', 'attack_direction', 'swing_path_tilt', 'intercept_ball_minus_batter_pos_x_inches', 'intercept_ball_minus_batter_pos_y_inches']\n"
     ]
    }
   ],
   "source": [
    "# This may take several minutes depending on connection and CPU\n",
    "all_data = []\n",
    "\n",
    "for start_date, end_date in date_ranges:\n",
    "    try:\n",
    "        df = statcast(start_dt=start_date, end_dt=end_date)\n",
    "        all_data.append(df)\n",
    "        print(f\"✅ Loaded: {start_date} to {end_date}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed for {start_date} to {end_date}: {e}\")\n",
    "\n",
    "statcast_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(f\"Shape of statcast_data: {statcast_data.shape}\")\n",
    "print(\"Preview of columns:\")\n",
    "print(statcast_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1461188e-16ad-4a08-913e-8af5b7a64ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Preview of labeled YRFI/NRFI data:\n",
      "   game_pk half_inning  label\n",
      "0   716352     Bot_1st      0\n",
      "1   716352     Top_1st      1\n",
      "2   716353     Bot_1st      1\n",
      "3   716353     Top_1st      1\n",
      "4   716354     Bot_1st      1\n"
     ]
    }
   ],
   "source": [
    "# Filter for 1st inning only\n",
    "inning_data = statcast_data[statcast_data['inning'] == 1].copy()\n",
    "\n",
    "# Create label column: run scored = YRFI (1), else NRFI (0)\n",
    "inning_data['half_inning'] = inning_data['inning_topbot'] + '_1st'\n",
    "\n",
    "# Group by game + half_inning and check if any runs were scored\n",
    "yrfi_labels = (\n",
    "    inning_data.groupby(['game_pk', 'half_inning'])\n",
    "    .agg(\n",
    "        runs_scored=('events', lambda x: any(ev in ['home_run', 'single', 'double', 'triple', 'field_error', 'sac_fly', 'grounded_into_double_play'] for ev in x.dropna())),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert to binary labels\n",
    "yrfi_labels['label'] = yrfi_labels['runs_scored'].astype(int)\n",
    "yrfi_labels.drop(columns='runs_scored', inplace=True)\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(\"Preview of labeled YRFI/NRFI data:\")\n",
    "print(yrfi_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "517aa5cf-26f9-438a-a510-1a8bca703ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Shape of pitcher data: (183, 394)\n",
      "Columns preview:\n",
      "['IDfg', 'Season', 'Name', 'Team', 'Age', 'W', 'L', 'WAR', 'ERA', 'G', 'GS', 'CG', 'ShO', 'SV', 'BS', 'IP', 'TBF', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'HBP', 'WP', 'BK', 'SO', 'GB', 'FB', 'LD', 'IFFB', 'Balls', 'Strikes', 'Pitches', 'RS', 'IFH', 'BU', 'BUH', 'K/9', 'BB/9', 'K/BB', 'H/9', 'HR/9', 'AVG', 'WHIP', 'BABIP', 'LOB%', 'FIP', 'GB/FB', 'LD%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'IFH%', 'BUH%', 'Starting', 'Start-IP', 'Relieving', 'Relief-IP', 'RAR', 'Dollars', 'tERA', 'xFIP', 'WPA', '-WPA', '+WPA', 'RE24', 'REW', 'pLI', 'inLI', 'gmLI', 'exLI', 'Pulls', 'WPA/LI', 'Clutch', 'FB% 2', 'FBv', 'SL%', 'SLv', 'CT%', 'CTv', 'CB%', 'CBv', 'CH%', 'CHv', 'SF%', 'SFv', 'KN%', 'KNv', 'XX%', 'PO%', 'wFB', 'wSL', 'wCT', 'wCB', 'wCH', 'wSF', 'wKN', 'wFB/C', 'wSL/C', 'wCT/C', 'wCB/C', 'wCH/C', 'wSF/C', 'wKN/C', 'O-Swing%', 'Z-Swing%', 'Swing%', 'O-Contact%', 'Z-Contact%', 'Contact%', 'Zone%', 'F-Strike%', 'SwStr%', 'HLD', 'SD', 'MD', 'ERA-', 'FIP-', 'xFIP-', 'K%', 'BB%', 'SIERA', 'RS/9', 'E-F', 'FA% (sc)', 'FT% (sc)', 'FC% (sc)', 'FS% (sc)', 'FO% (sc)', 'SI% (sc)', 'SL% (sc)', 'CU% (sc)', 'KC% (sc)', 'EP% (sc)', 'CH% (sc)', 'SC% (sc)', 'KN% (sc)', 'UN% (sc)', 'vFA (sc)', 'vFT (sc)', 'vFC (sc)', 'vFS (sc)', 'vFO (sc)', 'vSI (sc)', 'vSL (sc)', 'vCU (sc)', 'vKC (sc)', 'vEP (sc)', 'vCH (sc)', 'vSC (sc)', 'vKN (sc)', 'FA-X (sc)', 'FT-X (sc)', 'FC-X (sc)', 'FS-X (sc)', 'FO-X (sc)', 'SI-X (sc)', 'SL-X (sc)', 'CU-X (sc)', 'KC-X (sc)', 'EP-X (sc)', 'CH-X (sc)', 'SC-X (sc)', 'KN-X (sc)', 'FA-Z (sc)', 'FT-Z (sc)', 'FC-Z (sc)', 'FS-Z (sc)', 'FO-Z (sc)', 'SI-Z (sc)', 'SL-Z (sc)', 'CU-Z (sc)', 'KC-Z (sc)', 'EP-Z (sc)', 'CH-Z (sc)', 'SC-Z (sc)', 'KN-Z (sc)', 'wFA (sc)', 'wFT (sc)', 'wFC (sc)', 'wFS (sc)', 'wFO (sc)', 'wSI (sc)', 'wSL (sc)', 'wCU (sc)', 'wKC (sc)', 'wEP (sc)', 'wCH (sc)', 'wSC (sc)', 'wKN (sc)', 'wFA/C (sc)', 'wFT/C (sc)', 'wFC/C (sc)', 'wFS/C (sc)', 'wFO/C (sc)', 'wSI/C (sc)', 'wSL/C (sc)', 'wCU/C (sc)', 'wKC/C (sc)', 'wEP/C (sc)', 'wCH/C (sc)', 'wSC/C (sc)', 'wKN/C (sc)', 'O-Swing% (sc)', 'Z-Swing% (sc)', 'Swing% (sc)', 'O-Contact% (sc)', 'Z-Contact% (sc)', 'Contact% (sc)', 'Zone% (sc)', 'Pace', 'RA9-WAR', 'BIP-Wins', 'LOB-Wins', 'FDP-Wins', 'Age Rng', 'K-BB%', 'Pull%', 'Cent%', 'Oppo%', 'Soft%', 'Med%', 'Hard%', 'kwERA', 'TTO%', 'CH% (pi)', 'CS% (pi)', 'CU% (pi)', 'FA% (pi)', 'FC% (pi)', 'FS% (pi)', 'KN% (pi)', 'SB% (pi)', 'SI% (pi)', 'SL% (pi)', 'XX% (pi)', 'vCH (pi)', 'vCS (pi)', 'vCU (pi)', 'vFA (pi)', 'vFC (pi)', 'vFS (pi)', 'vKN (pi)', 'vSB (pi)', 'vSI (pi)', 'vSL (pi)', 'vXX (pi)', 'CH-X (pi)', 'CS-X (pi)', 'CU-X (pi)', 'FA-X (pi)', 'FC-X (pi)', 'FS-X (pi)', 'KN-X (pi)', 'SB-X (pi)', 'SI-X (pi)', 'SL-X (pi)', 'XX-X (pi)', 'CH-Z (pi)', 'CS-Z (pi)', 'CU-Z (pi)', 'FA-Z (pi)', 'FC-Z (pi)', 'FS-Z (pi)', 'KN-Z (pi)', 'SB-Z (pi)', 'SI-Z (pi)', 'SL-Z (pi)', 'XX-Z (pi)', 'wCH (pi)', 'wCS (pi)', 'wCU (pi)', 'wFA (pi)', 'wFC (pi)', 'wFS (pi)', 'wKN (pi)', 'wSB (pi)', 'wSI (pi)', 'wSL (pi)', 'wXX (pi)', 'wCH/C (pi)', 'wCS/C (pi)', 'wCU/C (pi)', 'wFA/C (pi)', 'wFC/C (pi)', 'wFS/C (pi)', 'wKN/C (pi)', 'wSB/C (pi)', 'wSI/C (pi)', 'wSL/C (pi)', 'wXX/C (pi)', 'O-Swing% (pi)', 'Z-Swing% (pi)', 'Swing% (pi)', 'O-Contact% (pi)', 'Z-Contact% (pi)', 'Contact% (pi)', 'Zone% (pi)', 'Pace (pi)', 'FRM', 'K/9+', 'BB/9+', 'K/BB+', 'H/9+', 'HR/9+', 'AVG+', 'WHIP+', 'BABIP+', 'LOB%+', 'K%+', 'BB%+', 'LD%+', 'GB%+', 'FB%+', 'HR/FB%+', 'Pull%+', 'Cent%+', 'Oppo%+', 'Soft%+', 'Med%+', 'Hard%+', 'EV', 'LA', 'Barrels', 'Barrel%', 'maxEV', 'HardHit', 'HardHit%', 'Events', 'CStr%', 'CSW%', 'xERA', 'botERA', 'botOvr CH', 'botStf CH', 'botCmd CH', 'botOvr CU', 'botStf CU', 'botCmd CU', 'botOvr FA', 'botStf FA', 'botCmd FA', 'botOvr SI', 'botStf SI', 'botCmd SI', 'botOvr SL', 'botStf SL', 'botCmd SL', 'botOvr KC', 'botStf KC', 'botCmd KC', 'botOvr FC', 'botStf FC', 'botCmd FC', 'botOvr FS', 'botStf FS', 'botCmd FS', 'botOvr', 'botStf', 'botCmd', 'botxRV100', 'Stf+ CH', 'Loc+ CH', 'Pit+ CH', 'Stf+ CU', 'Loc+ CU', 'Pit+ CU', 'Stf+ FA', 'Loc+ FA', 'Pit+ FA', 'Stf+ SI', 'Loc+ SI', 'Pit+ SI', 'Stf+ SL', 'Loc+ SL', 'Pit+ SL', 'Stf+ KC', 'Loc+ KC', 'Pit+ KC', 'Stf+ FC', 'Loc+ FC', 'Pit+ FC', 'Stf+ FS', 'Loc+ FS', 'Pit+ FS', 'Stuff+', 'Location+', 'Pitching+', 'Stf+ FO', 'Loc+ FO', 'Pit+ FO', 'season']\n"
     ]
    }
   ],
   "source": [
    "from pybaseball import pitching_stats\n",
    "\n",
    "# Pull pitcher season stats for 2023, 2024, 2025 so far\n",
    "pitchers_2023 = pitching_stats(2023)\n",
    "pitchers_2024 = pitching_stats(2024)\n",
    "pitchers_2025 = pitching_stats(2025)\n",
    "\n",
    "# Combine and tag year\n",
    "pitchers_2023['season'] = 2023\n",
    "pitchers_2024['season'] = 2024\n",
    "pitchers_2025['season'] = 2025\n",
    "\n",
    "pitcher_season_stats = pd.concat([pitchers_2023, pitchers_2024, pitchers_2025], ignore_index=True)\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(\"Shape of pitcher data:\", pitcher_season_stats.shape)\n",
    "print(\"Columns preview:\")\n",
    "print(pitcher_season_stats.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47218625-ae25-40ef-bef0-89928e72c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Nulls found in the following pitcher columns:\n",
      "SC-X (sc)    183\n",
      "SB-Z (pi)    183\n",
      "SC% (sc)     183\n",
      "EP-X (sc)    183\n",
      "SB% (pi)     183\n",
      "            ... \n",
      "FA-X (sc)      7\n",
      "vFA (pi)       7\n",
      "Pit+ FA        7\n",
      "Loc+ FA        7\n",
      "FA-X (pi)      7\n",
      "Length: 224, dtype: int64\n",
      "✅ Successfully ran ✔️\n"
     ]
    }
   ],
   "source": [
    "nulls_pitcher_stats = pitcher_season_stats.isnull().sum()\n",
    "nulls_pitcher_stats = nulls_pitcher_stats[nulls_pitcher_stats > 0].sort_values(ascending=False)\n",
    "\n",
    "if nulls_pitcher_stats.empty:\n",
    "    print(\"✅ No nulls in pitcher stats ✔️\")\n",
    "else:\n",
    "    print(\"⚠️ Nulls found in the following pitcher columns:\")\n",
    "    print(nulls_pitcher_stats)\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5872f0a7-765b-4f11-8106-e8ce1aac82c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved interim CSVs ✔️\n"
     ]
    }
   ],
   "source": [
    "# Save data to CSVs\n",
    "statcast_data.to_csv(\"statcast_2023_2025.csv\", index=False)\n",
    "yrfi_labels.to_csv(\"yrfi_labels.csv\", index=False)\n",
    "pitcher_season_stats.to_csv(\"pitcher_stats_season.csv\", index=False)\n",
    "\n",
    "print(\"✅ Successfully saved interim CSVs ✔️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "edf9ceef-b897-4f0f-8646-e93e2dd40531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Preview of rolling pitcher stats:\n",
      "       game_pk  pitcher game_date_start  hits_allowed  walks  strikeouts  \\\n",
      "16448   718288   425794      2023-05-06             8      0           5   \n",
      "15807   718211   425794      2023-05-12             7      1           2   \n",
      "15063   718124   425794      2023-05-18             5      3           1   \n",
      "14519   718059   425794      2023-05-23             8      1           2   \n",
      "13824   717975   425794      2023-05-29             9      2           6   \n",
      "\n",
      "       batters_faced  runs_allowed  hits_allowed_rolling3  walks_rolling3  \\\n",
      "16448              9             4               8.000000        0.000000   \n",
      "15807              9             4               7.500000        0.500000   \n",
      "15063              9             3               6.666667        1.333333   \n",
      "14519              9             5               6.666667        1.666667   \n",
      "13824              9             3               7.333333        2.000000   \n",
      "\n",
      "       strikeouts_rolling3  runs_allowed_rolling3  batters_faced_rolling3  \n",
      "16448             5.000000               4.000000                     9.0  \n",
      "15807             3.500000               4.000000                     9.0  \n",
      "15063             2.666667               3.666667                     9.0  \n",
      "14519             1.666667               4.000000                     9.0  \n",
      "13824             3.000000               3.666667                     9.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_30564\\2884826825.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df.assign(**{\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Ensure datetime formatting\n",
    "statcast_data['game_date'] = pd.to_datetime(statcast_data['game_date'])\n",
    "\n",
    "# STEP 2: Get start date per pitcher per game\n",
    "pitcher_starts = (\n",
    "    statcast_data\n",
    "    .groupby(['game_pk', 'pitcher'], as_index=False)\n",
    "    .agg(game_date_start=('game_date', 'min'))  # earliest pitch = start\n",
    ")\n",
    "\n",
    "# STEP 3: Merge into statcast data\n",
    "statcast_data = statcast_data.merge(pitcher_starts, on=['game_pk', 'pitcher'], how='left')\n",
    "\n",
    "# STEP 4: Per-game pitcher stats (use merged game_date_start)\n",
    "pitcher_game_stats = (\n",
    "    statcast_data.groupby(['game_pk', 'pitcher', 'game_date_start'])\n",
    "    .agg(\n",
    "        hits_allowed=('events', lambda x: sum(e in ['single', 'double', 'triple', 'home_run'] for e in x.dropna())),\n",
    "        walks=('events', lambda x: sum(e in ['walk', 'hit_by_pitch'] for e in x.dropna())),\n",
    "        strikeouts=('events', lambda x: sum(e == 'strikeout' for e in x.dropna())),\n",
    "        batters_faced=('batter', 'nunique'),\n",
    "        runs_allowed=('post_bat_score', lambda x: x.max() - x.min() if pd.notnull(x.max()) and pd.notnull(x.min()) else 0),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# STEP 5: Sort and compute rolling stats\n",
    "pitcher_game_stats = pitcher_game_stats.sort_values(['pitcher', 'game_date_start'])\n",
    "\n",
    "rolling_features = ['hits_allowed', 'walks', 'strikeouts', 'runs_allowed', 'batters_faced']\n",
    "\n",
    "rolling_stats = (\n",
    "    pitcher_game_stats\n",
    "    .groupby('pitcher', group_keys=False)\n",
    "    .apply(lambda df: df.assign(**{\n",
    "        f'{col}_rolling3': df[col].rolling(window=3, min_periods=1).mean()\n",
    "        for col in rolling_features\n",
    "    }))\n",
    ")\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(\"Preview of rolling pitcher stats:\")\n",
    "print(rolling_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31773268-6e67-41cc-a693-a16828b87bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rolling pitcher stats saved ✔️\n"
     ]
    }
   ],
   "source": [
    "pitcher_game_stats.to_csv(\"pitcher_rolling_stats.csv\", index=False)\n",
    "print(\"✅ Rolling pitcher stats saved ✔️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd607ba9-b299-40f1-a05e-b2b81332f783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Preview of batter rolling stats:\n",
      "   batter  game_date       AVG       OBP       SLG    K_rate  BB_rate  \\\n",
      "0  408234 2023-03-20  0.000000  0.000000  0.000000  0.333333      0.0   \n",
      "1  408234 2023-03-22  0.166667  0.166667  0.166667  0.166667      0.0   \n",
      "2  408234 2023-03-24  0.333333  0.333333  0.333333  0.111111      0.0   \n",
      "3  408234 2023-03-26  0.250000  0.250000  0.250000  0.166667      0.0   \n",
      "4  408234 2023-03-30  0.250000  0.250000  0.312500  0.125000      0.0   \n",
      "\n",
      "   rolling_PA  \n",
      "0         3.0  \n",
      "1         6.0  \n",
      "2         9.0  \n",
      "3        12.0  \n",
      "4        16.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_30564\\1675327081.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df.assign(\n"
     ]
    }
   ],
   "source": [
    "# Ensure dates are datetime\n",
    "statcast_data['game_date'] = pd.to_datetime(statcast_data['game_date'])\n",
    "\n",
    "# Sort by batter and date\n",
    "statcast_data = statcast_data.sort_values(['batter', 'game_date'])\n",
    "\n",
    "# Flag events\n",
    "statcast_data['is_hit'] = statcast_data['events'].isin(['single', 'double', 'triple', 'home_run']).astype(int)\n",
    "statcast_data['is_bb'] = statcast_data['events'].isin(['walk', 'hit_by_pitch']).astype(int)\n",
    "statcast_data['is_k'] = statcast_data['events'].eq('strikeout').astype(int)\n",
    "statcast_data['is_ab'] = statcast_data['events'].isin([\n",
    "    'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'force_out', 'grounded_into_double_play'\n",
    "]).astype(int)\n",
    "statcast_data['is_tb'] = statcast_data['events'].map({\n",
    "    'single': 1, 'double': 2, 'triple': 3, 'home_run': 4\n",
    "}).fillna(0)\n",
    "\n",
    "# Group by batter + game to get daily summaries\n",
    "batter_game_stats = (\n",
    "    statcast_data.groupby(['batter', 'game_date'])\n",
    "    .agg(\n",
    "        hits=('is_hit', 'sum'),\n",
    "        walks=('is_bb', 'sum'),\n",
    "        strikeouts=('is_k', 'sum'),\n",
    "        abs=('is_ab', 'sum'),\n",
    "        pa=('events', lambda x: x.notnull().sum()),\n",
    "        total_bases=('is_tb', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rolling over last 5 games\n",
    "batter_game_stats = batter_game_stats.sort_values(['batter', 'game_date'])\n",
    "\n",
    "rolling = (\n",
    "    batter_game_stats\n",
    "    .groupby('batter', group_keys=False)\n",
    "    .apply(lambda df: df.assign(\n",
    "        AVG=df['hits'].rolling(5, min_periods=1).sum() / df['abs'].rolling(5, min_periods=1).sum(),\n",
    "        OBP=(df['hits'].rolling(5, min_periods=1).sum() + df['walks'].rolling(5, min_periods=1).sum()) / df['pa'].rolling(5, min_periods=1).sum(),\n",
    "        SLG=df['total_bases'].rolling(5, min_periods=1).sum() / df['abs'].rolling(5, min_periods=1).sum(),\n",
    "        K_rate=df['strikeouts'].rolling(5, min_periods=1).sum() / df['pa'].rolling(5, min_periods=1).sum(),\n",
    "        BB_rate=df['walks'].rolling(5, min_periods=1).sum() / df['pa'].rolling(5, min_periods=1).sum(),\n",
    "        rolling_PA=df['pa'].rolling(5, min_periods=1).sum()\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Filter only necessary columns\n",
    "batter_rolling_form = rolling[['batter', 'game_date', 'AVG', 'OBP', 'SLG', 'K_rate', 'BB_rate', 'rolling_PA']]\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(\"Preview of batter rolling stats:\")\n",
    "print(batter_rolling_form.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f0baff78-5d11-40b9-9960-d35bcbfdccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved batter rolling stats ✔️\n"
     ]
    }
   ],
   "source": [
    "batter_rolling_form.to_csv(\"batter_rolling_stats.csv\", index=False)\n",
    "print(\"✅ Saved batter rolling stats ✔️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8286e048-8e17-4785-961d-bab09dca556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully ran ✔️\n",
      "Preview of rolling team offense:\n",
      "  team  game_date half_inning  runs_1st  hits  walks  strikeouts  abs  pa  \\\n",
      "0  ATH 2025-03-15     Bot_1st         0     0      0           0    3   3   \n",
      "1  ATH 2025-03-15     Top_1st         0     2      0           0    4   4   \n",
      "2  ATH 2025-03-16     Top_1st         0     0      0           1    3   3   \n",
      "3  ATH 2025-03-17     Bot_1st         0     1      0           0    4   4   \n",
      "4  ATH 2025-03-19     Top_1st         0     0      1           0    3   4   \n",
      "\n",
      "   total_bases  runs_rolling10       OBP       SLG    K_rate   BB_rate  \n",
      "0          0.0             0.0  0.000000  0.000000  0.000000  0.000000  \n",
      "1          2.0             0.0  0.285714  0.285714  0.000000  0.000000  \n",
      "2          0.0             0.0  0.200000  0.200000  0.100000  0.000000  \n",
      "3          2.0             0.0  0.214286  0.285714  0.071429  0.000000  \n",
      "4          0.0             0.0  0.222222  0.235294  0.055556  0.055556  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_30564\\2540919810.py:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df.assign(\n"
     ]
    }
   ],
   "source": [
    "# Ensure datetime\n",
    "statcast_data['game_date'] = pd.to_datetime(statcast_data['game_date'])\n",
    "\n",
    "# Create 'bat_team' from home/away + inning_topbot\n",
    "statcast_data['bat_team'] = statcast_data['home_team']\n",
    "statcast_data.loc[statcast_data['inning_topbot'] == 'Top', 'bat_team'] = statcast_data['away_team']\n",
    "\n",
    "# Filter to 1st inning\n",
    "inning_1_data = statcast_data[statcast_data['inning'] == 1].copy()\n",
    "\n",
    "# Add half-inning for team context\n",
    "inning_1_data['half_inning'] = inning_1_data['inning_topbot'] + '_1st'\n",
    "inning_1_data['team'] = inning_1_data['bat_team']\n",
    "\n",
    "# Total bases for SLG\n",
    "inning_1_data['bases'] = inning_1_data['events'].map({\n",
    "    'single': 1, 'double': 2, 'triple': 3, 'home_run': 4\n",
    "}).fillna(0)\n",
    "\n",
    "# Flags for ratios\n",
    "inning_1_data['is_hit'] = inning_1_data['events'].isin(['single', 'double', 'triple', 'home_run']).astype(int)\n",
    "inning_1_data['is_bb'] = inning_1_data['events'].isin(['walk', 'hit_by_pitch']).astype(int)\n",
    "inning_1_data['is_k'] = inning_1_data['events'].eq('strikeout').astype(int)\n",
    "inning_1_data['is_ab'] = inning_1_data['events'].isin([\n",
    "    'single', 'double', 'triple', 'home_run', 'strikeout', 'field_out', 'force_out', 'grounded_into_double_play'\n",
    "]).astype(int)\n",
    "inning_1_data['is_pa'] = inning_1_data['events'].notnull().astype(int)\n",
    "\n",
    "# 1st inning team performance per game\n",
    "team_1st_inning_stats = (\n",
    "    inning_1_data\n",
    "    .groupby(['team', 'game_date', 'half_inning'])\n",
    "    .agg(\n",
    "        runs_1st=('post_bat_score', lambda x: x.max() - x.min() if pd.notnull(x.max()) and pd.notnull(x.min()) else 0),\n",
    "        hits=('is_hit', 'sum'),\n",
    "        walks=('is_bb', 'sum'),\n",
    "        strikeouts=('is_k', 'sum'),\n",
    "        abs=('is_ab', 'sum'),\n",
    "        pa=('is_pa', 'sum'),\n",
    "        total_bases=('bases', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort for rolling\n",
    "team_1st_inning_stats = team_1st_inning_stats.sort_values(['team', 'game_date'])\n",
    "\n",
    "# Compute rolling stats per team\n",
    "rolling_team = (\n",
    "    team_1st_inning_stats\n",
    "    .groupby('team', group_keys=False)\n",
    "    .apply(lambda df: df.assign(\n",
    "        runs_rolling10=df['runs_1st'].rolling(10, min_periods=1).mean(),\n",
    "        OBP=(df['hits'].rolling(10, min_periods=1).sum() + df['walks'].rolling(10, min_periods=1).sum()) / df['pa'].rolling(10, min_periods=1).sum(),\n",
    "        SLG=(df['total_bases'].rolling(10, min_periods=1).sum()) / df['abs'].rolling(10, min_periods=1).sum(),\n",
    "        K_rate=df['strikeouts'].rolling(10, min_periods=1).sum() / df['pa'].rolling(10, min_periods=1).sum(),\n",
    "        BB_rate=df['walks'].rolling(10, min_periods=1).sum() / df['pa'].rolling(10, min_periods=1).sum()\n",
    "    ))\n",
    ")\n",
    "\n",
    "print(\"✅ Successfully ran ✔️\")\n",
    "print(\"Preview of rolling team offense:\")\n",
    "print(rolling_team.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7eb2bea-ed0d-4167-aea1-e317a89f0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved team 1st inning offense stats ✔️\n"
     ]
    }
   ],
   "source": [
    "rolling_team.to_csv(\"team_1st_inning_offense.csv\", index=False)\n",
    "print(\"✅ Saved team 1st inning offense stats ✔️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cc3892b-9366-484f-af3a-6aaac7caa880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSVs loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload saved CSVs\n",
    "df_final = pd.read_csv(\"yrfi_labels.csv\")\n",
    "statcast = pd.read_csv(\"statcast_2023_2025.csv\", parse_dates=['game_date'])\n",
    "pitcher_form = pd.read_csv(\"pitcher_rolling_stats.csv\", parse_dates=['game_date_start'])\n",
    "pitcher_season = pd.read_csv(\"pitcher_stats_season.csv\")\n",
    "team_offense = pd.read_csv(\"team_1st_inning_offense.csv\", parse_dates=['game_date'])\n",
    "\n",
    "print(\"✅ CSVs loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f99b1a5-3cc4-4691-8cac-6ae385f38800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Game info and ID mapping done — 12591 / 12620 pitchers mapped to FanGraphs\n"
     ]
    }
   ],
   "source": [
    "from pybaseball import playerid_reverse_lookup\n",
    "\n",
    "# Add inning context\n",
    "df_final['inning_topbot'] = df_final['half_inning'].str.extract(r'^(Top|Bot)')\n",
    "df_final['inning'] = 1\n",
    "\n",
    "# Merge game info from statcast\n",
    "statcast['game_date'] = pd.to_datetime(statcast['game_date'])\n",
    "game_info = (\n",
    "    statcast[statcast['inning'] == 1]\n",
    "    .groupby(['game_pk', 'inning_topbot'])\n",
    "    .agg(\n",
    "        game_date=('game_date', 'first'),\n",
    "        pitcher=('pitcher', 'first'),\n",
    "        home_team=('home_team', 'first'),\n",
    "        away_team=('away_team', 'first')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "game_info['team'] = game_info.apply(\n",
    "    lambda row: row['away_team'] if row['inning_topbot'] == 'Top' else row['home_team'], axis=1\n",
    ")\n",
    "\n",
    "df_final = df_final.merge(\n",
    "    game_info[['game_pk', 'inning_topbot', 'game_date', 'pitcher', 'team']],\n",
    "    on=['game_pk', 'inning_topbot'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ID mapping\n",
    "unique_pitchers = df_final['pitcher'].dropna().unique().tolist()\n",
    "id_map = playerid_reverse_lookup(unique_pitchers)\n",
    "id_map = id_map.rename(columns={'key_mlbam': 'pitcher', 'key_fangraphs': 'IDfg'})\n",
    "id_map = id_map[['pitcher', 'IDfg']].dropna().astype(int)\n",
    "\n",
    "df_final = df_final.merge(id_map, on='pitcher', how='left')\n",
    "\n",
    "# Confirm mapping\n",
    "mapped = df_final['IDfg'].notnull().sum()\n",
    "print(f\"✅ Game info and ID mapping done — {mapped} / {len(df_final)} pitchers mapped to FanGraphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98c0a1ad-158e-4a48-a163-a32135d23d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged pitcher_form — rows: 12620\n",
      "✅ Merged pitcher_season — rows: 12620\n",
      "✅ Merged team_offense — rows: 12620\n",
      "✅ All merges complete — ready for audit\n",
      "Rows: 12620 | Columns: 35\n",
      "   game_pk half_inning  label inning_topbot  inning  game_date  pitcher team  \\\n",
      "0   716352     Bot_1st      0           Bot       1 2023-10-01   650633   KC   \n",
      "1   716352     Top_1st      1           Top       1 2023-10-01   425844  NYY   \n",
      "2   716353     Bot_1st      1           Bot       1 2023-10-01   668881  STL   \n",
      "3   716353     Top_1st      1           Top       1 2023-10-01   571945  CIN   \n",
      "4   716354     Bot_1st      1           Bot       1 2023-10-01   671131  ATL   \n",
      "\n",
      "   season  hits_allowed  ...  strikeouts  abs  pa  total_bases  \\\n",
      "0    2023             8  ...           1    3   3          0.0   \n",
      "1    2023             4  ...           0    5   5          3.0   \n",
      "2    2023             9  ...           2    4   4          1.0   \n",
      "3    2023             7  ...           2    4   4          4.0   \n",
      "4    2023             5  ...           2    5   7          3.0   \n",
      "\n",
      "   runs_rolling10_team  OBP_team  SLG_team  K_rate_team  BB_rate_team  \\\n",
      "0                  1.9  0.448276  0.666667     0.206897      0.086207   \n",
      "1                  0.3  0.317073  0.368421     0.195122      0.073171   \n",
      "2                  0.5  0.309524  0.351351     0.142857      0.119048   \n",
      "3                  0.7  0.340909  0.540541     0.272727      0.159091   \n",
      "4                  0.9  0.340000  0.652174     0.240000      0.040000   \n",
      "\n",
      "   is_home_team  \n",
      "0          True  \n",
      "1         False  \n",
      "2          True  \n",
      "3         False  \n",
      "4          True  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# ✅ KEYS & PREP\n",
    "# -------------------------------------\n",
    "df_final['half_inning'] = df_final['inning_topbot'] + '_1st'\n",
    "df_final['season'] = pd.to_datetime(df_final['game_date']).dt.year\n",
    "df_final['game_date_start'] = pd.to_datetime(df_final['game_date'])  # Ensure key for pitcher_form merge\n",
    "\n",
    "# -------------------------------------\n",
    "# ✅ MERGE: PITCHER ROLLING STATS\n",
    "# -------------------------------------\n",
    "form_cols = ['pitcher', 'game_date_start', 'hits_allowed', 'walks', 'strikeouts', 'batters_faced', 'runs_allowed']\n",
    "df_final = df_final.merge(\n",
    "    pitcher_form[form_cols],\n",
    "    on=['pitcher', 'game_date_start'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"✅ Merged pitcher_form — rows: {df_final.shape[0]}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# ✅ MERGE: PITCHER SEASON STATS\n",
    "# -------------------------------------\n",
    "pitcher_season = pitcher_season.loc[:, ~pitcher_season.columns.duplicated()].copy()\n",
    "\n",
    "season_cols = ['IDfg', 'Season', 'ERA', 'WHIP', 'FIP', 'K/9', 'BB/9', 'xFIP', 'CSW%', 'xERA']\n",
    "season_renamed = pitcher_season[season_cols].rename(columns={\n",
    "    col: f\"{col}_season\" for col in season_cols if col not in ['IDfg', 'Season']\n",
    "})\n",
    "\n",
    "df_final = df_final.merge(\n",
    "    season_renamed,\n",
    "    left_on=['IDfg', 'season'],\n",
    "    right_on=['IDfg', 'Season'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"✅ Merged pitcher_season — rows: {df_final.shape[0]}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# ✅ MERGE: TEAM OFFENSE STATS\n",
    "# -------------------------------------\n",
    "team_offense_clean = team_offense.rename(columns={\n",
    "    'OBP': 'OBP_team', 'SLG': 'SLG_team',\n",
    "    'K_rate': 'K_rate_team', 'BB_rate': 'BB_rate_team',\n",
    "    'runs_rolling10': 'runs_rolling10_team'\n",
    "})\n",
    "df_final = df_final.merge(\n",
    "    team_offense_clean,\n",
    "    on=['team', 'game_date', 'half_inning'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"✅ Merged team_offense — rows: {df_final.shape[0]}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# ✅ FINAL FEATURES & CLEAN-UP\n",
    "# -------------------------------------\n",
    "df_final['is_home_team'] = df_final['inning_topbot'] == 'Bot'\n",
    "\n",
    "# Drop temp columns\n",
    "df_final = df_final.drop(columns=['IDfg', 'Season', 'game_date_start'], errors='ignore')\n",
    "\n",
    "# Clean suffixes\n",
    "df_final.columns = df_final.columns.str.replace(r'_x$|_y$', '', regex=True)\n",
    "\n",
    "# Do NOT dropna yet — we'll audit in the next cell\n",
    "print(\"✅ All merges complete — ready for audit\")\n",
    "print(\"Rows:\", df_final.shape[0], \"| Columns:\", df_final.shape[1])\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8be49091-974e-458c-b05e-6c26abe478b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Row count BEFORE dropna: 12620\n",
      "\n",
      "🔍 Top columns with nulls:\n",
      "K/9_season     8264\n",
      "CSW%_season    8264\n",
      "BB/9_season    8264\n",
      "xERA_season    8264\n",
      "FIP_season     8264\n",
      "WHIP_season    8264\n",
      "ERA_season     8264\n",
      "xFIP_season    8264\n",
      "dtype: int64\n",
      "\n",
      "✅ Rows remaining after dropna on key columns: 4356\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Row count BEFORE dropna:\", df_final.shape[0])\n",
    "\n",
    "# Print top 20 columns with nulls\n",
    "null_counts = df_final.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\n🔍 Top columns with nulls:\")\n",
    "print(null_counts[null_counts > 0].head(20))\n",
    "\n",
    "# Test how many rows we'd keep if we dropped just on key stat columns\n",
    "key_cols = ['ERA_season', 'WHIP_season', 'OBP_team', 'SLG_team', 'runs_rolling10_team']\n",
    "df_filtered = df_final.dropna(subset=key_cols)\n",
    "print(f\"\\n✅ Rows remaining after dropna on key columns: {df_filtered.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31957327-6f36-4853-83ec-7eb409528244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved (no leakage features)\n",
      "Rows: 4356 | Columns: 30\n",
      "    game_pk half_inning  label inning_topbot  inning  game_date  pitcher team  \\\n",
      "3    716353     Top_1st      1           Top       1 2023-10-01   571945  CIN   \n",
      "12   716358     Bot_1st      0           Bot       1 2023-10-01   664299   AZ   \n",
      "16   716360     Bot_1st      0           Bot       1 2023-10-01   641540  SEA   \n",
      "17   716360     Top_1st      0           Top       1 2023-10-01   669923  TEX   \n",
      "18   716361     Bot_1st      1           Bot       1 2023-10-01   608337  DET   \n",
      "\n",
      "    season  hits_allowed  ...  CSW%_season  xERA_season  walks  strikeouts  \\\n",
      "3     2023             7  ...        0.250         5.44      0           2   \n",
      "12    2023             3  ...        0.252         4.42      0           0   \n",
      "16    2023             4  ...        0.274         4.48      0           2   \n",
      "17    2023             3  ...        0.273         3.90      0           1   \n",
      "18    2023             7  ...        0.288         4.61      1           1   \n",
      "\n",
      "    runs_rolling10_team  OBP_team  SLG_team  K_rate_team  BB_rate_team  \\\n",
      "3                   0.7  0.340909  0.540541     0.272727      0.159091   \n",
      "12                  0.5  0.285714  0.205882     0.166667      0.142857   \n",
      "16                  0.1  0.142857  0.218750     0.314286      0.057143   \n",
      "17                  0.4  0.317073  0.486486     0.268293      0.097561   \n",
      "18                  0.3  0.309524  0.435897     0.190476      0.047619   \n",
      "\n",
      "    is_home_team  \n",
      "3          False  \n",
      "12          True  \n",
      "16          True  \n",
      "17         False  \n",
      "18          True  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# ✅ Cell 17.5 — Remove outcome-based leakage features\n",
    "# -------------------------------------\n",
    "\n",
    "# These features leak actual 1st-inning results (not predictive)\n",
    "leaky_cols = ['hits', 'abs', 'total_bases', 'walks.1', 'pa', 'runs_1st']\n",
    "\n",
    "# Drop them\n",
    "df_final = df_final.drop(columns=leaky_cols, errors='ignore')\n",
    "\n",
    "# Rebuild your cleaned training set using the same key stat filter\n",
    "important_cols = ['ERA_season', 'WHIP_season', 'OBP_team', 'SLG_team', 'runs_rolling10_team']\n",
    "df_model = df_final.dropna(subset=important_cols)\n",
    "\n",
    "# Save to new file\n",
    "df_model.to_csv(\"final_training_data_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"✅ Cleaned dataset saved (no leakage features)\")\n",
    "print(\"Rows:\", df_model.shape[0], \"| Columns:\", df_model.shape[1])\n",
    "print(df_model.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c5971f5-85cc-4c1e-a1bd-5cc8853f81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved clean training dataset: final_training_data_clean_final.csv\n",
      "Rows: 4344 | Columns: 23\n"
     ]
    }
   ],
   "source": [
    "# 📦 Cell 17.6 — Build leak-free training dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load your final joined dataset\n",
    "df = pd.read_csv(\"final_training_data.csv\")\n",
    "\n",
    "# Columns to keep (true predictors, no leakage)\n",
    "trusted_cols = [\n",
    "    'inning', 'pitcher', 'season',\n",
    "    'hits_allowed', 'walks', 'strikeouts', 'batters_faced', 'runs_allowed',\n",
    "    'ERA_season', 'WHIP_season', 'FIP_season', 'K/9_season', 'BB/9_season',\n",
    "    'xFIP_season', 'CSW%_season', 'xERA_season',\n",
    "    'runs_rolling10_team', 'OBP_team', 'SLG_team', 'K_rate_team', 'BB_rate_team',\n",
    "    'is_home_team', 'label'\n",
    "]\n",
    "\n",
    "# Filter\n",
    "df_clean = df[trusted_cols].dropna()\n",
    "\n",
    "# Save clean dataset\n",
    "df_clean.to_csv(\"final_training_data_clean_final.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved clean training dataset: final_training_data_clean_final.csv\")\n",
    "print(\"Rows:\", df_clean.shape[0], \"| Columns:\", df_clean.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec59107-6776-4e6d-87db-7056360c7aab",
   "metadata": {},
   "source": [
    "XGBOOST TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2962926-f0db-4d8e-90f9-05482afe395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model retrained on leak-free data\n",
      "Accuracy: 0.6548\n",
      "AUC: 0.7097\n",
      "F1: 0.7387\n",
      "Log Loss: 0.6038\n"
     ]
    }
   ],
   "source": [
    "# 📦 Cell 18 — Retrain model on clean data\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load clean data\n",
    "df = pd.read_csv(\"final_training_data_clean_final.csv\")\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Time-split (realistic)\n",
    "df = df.sort_values(\"season\")  # season is our proxy for time\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=[(dtrain, 'train'), (dtest, 'eval')],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save_model(\"xgboost_yrfi_final.json\")\n",
    "\n",
    "# Eval\n",
    "y_pred_proba = model.predict(dtest)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"✅ Model retrained on leak-free data\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
    "print(\"AUC:\", round(roc_auc_score(y_test, y_pred_proba), 4))\n",
    "print(\"F1:\", round(f1_score(y_test, y_pred), 4))\n",
    "print(\"Log Loss:\", round(log_loss(y_test, y_pred_proba), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3938a22-5ff0-4df9-bb7a-77e8bb1e7b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8102acb3-cc4e-4a8d-bef8-1e23336625ea",
   "metadata": {},
   "source": [
    "BUILD FOR TODAYS PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56c74aa2-86d5-46d8-8d02-ce46048af7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: xgboost_yrfi_final.json\n"
     ]
    }
   ],
   "source": [
    "# 📦 Cell 19 — Load leak-free model for prediction\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.Booster()\n",
    "model.load_model(\"xgboost_yrfi_final.json\")\n",
    "\n",
    "print(\"✅ Loaded model: xgboost_yrfi_final.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fe48be48-8c99-4425-8296-74f70e3e7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# ✅ Cell 20 — Start Today's Matchups Pipeline\n",
    "# -------------------------------------\n",
    "import statsapi\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "schedule = statsapi.schedule(date=today)\n",
    "\n",
    "rows = []\n",
    "for game in schedule:\n",
    "    home_pitcher = game.get('home_probable_pitcher')\n",
    "    away_pitcher = game.get('away_probable_pitcher')\n",
    "    if home_pitcher and away_pitcher:\n",
    "        rows.append({\n",
    "            'game_id': game['game_id'],\n",
    "            'game_date': today,\n",
    "            'home_team': game['home_name'],\n",
    "            'away_team': game['away_name'],\n",
    "            'home_pitcher': home_pitcher,\n",
    "            'away_pitcher': away_pitcher\n",
    "        })\n",
    "\n",
    "today_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "824091b6-b804-4f53-bcad-bd83ba970be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rebuilt today_games:\n",
      "   game_pk   game_date                  team        pitcher_name  \\\n",
      "0   777640  2025-06-05  Arizona Diamondbacks        Grant Holmes   \n",
      "1   777640  2025-06-05        Atlanta Braves      Brandon Pfaadt   \n",
      "2   777642  2025-06-05    Kansas City Royals       Miles Mikolas   \n",
      "3   777642  2025-06-05   St. Louis Cardinals        Noah Cameron   \n",
      "4   777635  2025-06-05    Kansas City Royals  Matthew Liberatore   \n",
      "\n",
      "  inning_topbot half_inning  \n",
      "0           Top     Top_1st  \n",
      "1           Bot     Bot_1st  \n",
      "2           Top     Top_1st  \n",
      "3           Bot     Bot_1st  \n",
      "4           Top     Top_1st  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# ✅ Cell 21 — Explode Matchups into Half-Innings\n",
    "# -------------------------------------\n",
    "half_innings = []\n",
    "for _, row in today_df.iterrows():\n",
    "    half_innings.append({\n",
    "        'game_pk': row['game_id'],\n",
    "        'game_date': row['game_date'],\n",
    "        'team': row['away_team'],\n",
    "        'pitcher_name': row['home_pitcher'],\n",
    "        'inning_topbot': 'Top'\n",
    "    })\n",
    "    half_innings.append({\n",
    "        'game_pk': row['game_id'],\n",
    "        'game_date': row['game_date'],\n",
    "        'team': row['home_team'],\n",
    "        'pitcher_name': row['away_pitcher'],\n",
    "        'inning_topbot': 'Bot'\n",
    "    })\n",
    "\n",
    "today_games = pd.DataFrame(half_innings)\n",
    "today_games['half_inning'] = today_games['inning_topbot'] + '_1st'\n",
    "print(\"✅ Rebuilt today_games:\")\n",
    "print(today_games.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a52abcaf-0146-4d51-9f5d-1b1acbe6c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mapped pitchers:\n",
      "          pitcher_name   pitcher\n",
      "0         Grant Holmes  656550.0\n",
      "1       Brandon Pfaadt  680694.0\n",
      "2        Miles Mikolas  572070.0\n",
      "4   Matthew Liberatore  669461.0\n",
      "8        Chris Bassitt  605135.0\n",
      "13          Zach Eflin  621107.0\n",
      "15         Dylan Cease  656546.0\n",
      "18        Mitch Keller  641745.0\n",
      "19      Framber Valdez  664285.0\n",
      "20          Jake Irvin  676600.0\n",
      "22           Max Fried  621112.0\n",
      "24         Ryan Pepiot  675632.0\n",
      "25         Jack Leiter  680678.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# ✅ Cell 22 — Map Pitchers and Predict YRFI/NRFI\n",
    "# -------------------------------------\n",
    "manual_ids = {\n",
    "    'brandon pfaadt': 680694,\n",
    "    'grant holmes': 656550,\n",
    "    'miles mikolas': 572070,\n",
    "    'matthew liberatore': 669461,\n",
    "    'chris bassitt': 605135,\n",
    "    'framber valdez': 664285,\n",
    "    'zach eflin': 621107,\n",
    "    'dylan cease': 656546,\n",
    "    'mitch keller': 641745,\n",
    "    'jake irvin': 676600,\n",
    "    'max fried': 621112,\n",
    "    'jack leiter': 680678,\n",
    "    'ryan pepiot': 675632\n",
    "}\n",
    "\n",
    "today_games['pitcher_key'] = today_games['pitcher_name'].str.strip().str.lower()\n",
    "today_games['pitcher'] = today_games['pitcher_key'].map(manual_ids)\n",
    "today_games = today_games.dropna(subset=['pitcher'])\n",
    "print(\"✅ Mapped pitchers:\")\n",
    "print(today_games[['pitcher_name', 'pitcher']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae2cfbda-e647-499d-97a3-a30d15c9c209",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Team offense features merged into today_pred:\n",
      "  team_abbr  OBP_team  runs_rolling10_team\n",
      "0        AZ       NaN                  NaN\n",
      "1       ATL       NaN                  NaN\n",
      "2        KC       NaN                  NaN\n",
      "3       STL       NaN                  NaN\n",
      "4        KC       NaN                  NaN\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# ✅ Cell 23.1 — Merge Team Offense Stats (leak-free, type-safe)\n",
    "# -------------------------------------\n",
    "\n",
    "# Step 1: Map full team names to 3-letter codes\n",
    "team_map = {\n",
    "    'Arizona Diamondbacks': 'AZ',\n",
    "    'Atlanta Braves': 'ATL',\n",
    "    'Baltimore Orioles': 'BAL',\n",
    "    'Boston Red Sox': 'BOS',\n",
    "    'Chicago Cubs': 'CHC',\n",
    "    'Chicago White Sox': 'CWS',\n",
    "    'Cincinnati Reds': 'CIN',\n",
    "    'Cleveland Guardians': 'CLE',\n",
    "    'Colorado Rockies': 'COL',\n",
    "    'Detroit Tigers': 'DET',\n",
    "    'Houston Astros': 'HOU',\n",
    "    'Kansas City Royals': 'KC',\n",
    "    'Los Angeles Angels': 'LAA',\n",
    "    'Los Angeles Dodgers': 'LAD',\n",
    "    'Miami Marlins': 'MIA',\n",
    "    'Milwaukee Brewers': 'MIL',\n",
    "    'Minnesota Twins': 'MIN',\n",
    "    'New York Mets': 'NYM',\n",
    "    'New York Yankees': 'NYY',\n",
    "    'Oakland Athletics': 'ATH',\n",
    "    'Philadelphia Phillies': 'PHI',\n",
    "    'Pittsburgh Pirates': 'PIT',\n",
    "    'San Diego Padres': 'SD',\n",
    "    'San Francisco Giants': 'SF',\n",
    "    'Seattle Mariners': 'SEA',\n",
    "    'St. Louis Cardinals': 'STL',\n",
    "    'Tampa Bay Rays': 'TB',\n",
    "    'Texas Rangers': 'TEX',\n",
    "    'Toronto Blue Jays': 'TOR',\n",
    "    'Washington Nationals': 'WSH'\n",
    "}\n",
    "\n",
    "\n",
    "# Map full team names to abbreviations\n",
    "today_games['team_abbr'] = today_games['team'].map(team_map)\n",
    "\n",
    "# Step 2: Prepare and rename team offense stats\n",
    "team_offense_clean = team_offense.rename(columns={\n",
    "    'OBP': 'OBP_team', 'SLG': 'SLG_team',\n",
    "    'K_rate': 'K_rate_team', 'BB_rate': 'BB_rate_team',\n",
    "    'runs_rolling10': 'runs_rolling10_team'\n",
    "})\n",
    "\n",
    "# Step 3: Make sure game_date is datetime in both\n",
    "today_games['game_date'] = pd.to_datetime(today_games['game_date'])\n",
    "team_offense_clean['game_date'] = pd.to_datetime(team_offense_clean['game_date'])\n",
    "\n",
    "# Step 4: Merge team offense stats\n",
    "today_pred = today_games.merge(\n",
    "    team_offense_clean,\n",
    "    left_on=['team_abbr', 'game_date', 'half_inning'],\n",
    "    right_on=['team', 'game_date', 'half_inning'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Confirm result\n",
    "print(\"✅ Team offense features merged into today_pred:\")\n",
    "print(today_pred[['team_abbr', 'OBP_team', 'runs_rolling10_team']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "38f95ab8-dfd9-4af1-b97e-203aeda1a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final YRFI/NRFI Predictions:\n",
      "                     team        pitcher_name    P_YRFI    P_NRFI   Confidence\n",
      "4   Philadelphia Phillies       Chris Bassitt  0.897836  0.102164  🔥 High YRFI\n",
      "8      Pittsburgh Pirates      Framber Valdez  0.880481  0.119519  🔥 High YRFI\n",
      "5        Seattle Mariners          Zach Eflin  0.871476  0.128524  🔥 High YRFI\n",
      "10    Cleveland Guardians           Max Fried  0.868979  0.131021  🔥 High YRFI\n",
      "7          Houston Astros        Mitch Keller  0.866018  0.133982  🔥 High YRFI\n",
      "2      Kansas City Royals       Miles Mikolas  0.863790  0.136210  🔥 High YRFI\n",
      "6    San Francisco Giants         Dylan Cease  0.848261  0.151739  🔥 High YRFI\n",
      "9            Chicago Cubs          Jake Irvin  0.846022  0.153978  🔥 High YRFI\n",
      "11          Texas Rangers         Ryan Pepiot  0.846022  0.153978  🔥 High YRFI\n",
      "0    Arizona Diamondbacks        Grant Holmes  0.845392  0.154608  🔥 High YRFI\n",
      "3      Kansas City Royals  Matthew Liberatore  0.838289  0.161711  🔥 High YRFI\n",
      "1          Atlanta Braves      Brandon Pfaadt  0.828293  0.171707  🔥 High YRFI\n",
      "12         Tampa Bay Rays         Jack Leiter  0.828293  0.171707  🔥 High YRFI\n"
     ]
    }
   ],
   "source": [
    "# 📦 Cell 23 — Predict YRFI/NRFI using clean model\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Get model's expected features\n",
    "expected_features = model.feature_names\n",
    "\n",
    "# Step 2: Build feature matrix from today_pred\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for col in expected_features:\n",
    "    if col in today_pred.columns:\n",
    "        X[col] = today_pred[col]\n",
    "    else:\n",
    "        X[col] = 0  # Fill missing cols with 0s\n",
    "\n",
    "X = X[expected_features]  # Match order\n",
    "\n",
    "# Step 3: Predict\n",
    "dmat = xgb.DMatrix(X)\n",
    "today_pred['P_YRFI'] = model.predict(dmat)\n",
    "today_pred['P_NRFI'] = 1 - today_pred['P_YRFI']\n",
    "\n",
    "# Step 4: Add confidence levels\n",
    "def label_conf(p):\n",
    "    if p >= 0.75:\n",
    "        return \"🔥 High YRFI\"\n",
    "    elif p >= 0.65:\n",
    "        return \"⚠️ Moderate YRFI\"\n",
    "    elif p <= 0.35:\n",
    "        return \"🧊 Moderate NRFI\"\n",
    "    elif p <= 0.25:\n",
    "        return \"❄️ High NRFI\"\n",
    "    else:\n",
    "        return \"❓ Low Confidence\"\n",
    "\n",
    "today_pred['Confidence'] = today_pred['P_YRFI'].apply(label_conf)\n",
    "\n",
    "# Step 5: Output\n",
    "results = today_pred[['team', 'pitcher_name', 'P_YRFI', 'P_NRFI', 'Confidence']]\n",
    "results = results.sort_values('P_YRFI', ascending=False)\n",
    "\n",
    "print(\"✅ Final YRFI/NRFI Predictions:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "addeb0ce-f596-4b8f-8362-55c84050a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Mean values of features in today’s input (X):\n",
      "walks                       0.000000\n",
      "strikeouts                  0.000000\n",
      "CSW%_season                 0.282000\n",
      "is_home_team                0.384615\n",
      "WHIP_season                 1.160000\n",
      "BB/9_season                 2.023333\n",
      "FIP_season                  3.153333\n",
      "xFIP_season                 3.276667\n",
      "ERA_season                  3.333333\n",
      "xERA_season                 3.553333\n",
      "K/9_season                  8.536667\n",
      "season                   2025.000000\n",
      "pitcher                647816.538462\n",
      "inning                           NaN\n",
      "hits_allowed                     NaN\n",
      "batters_faced                    NaN\n",
      "runs_allowed                     NaN\n",
      "runs_rolling10_team              NaN\n",
      "OBP_team                         NaN\n",
      "SLG_team                         NaN\n",
      "K_rate_team                      NaN\n",
      "BB_rate_team                     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"🧪 Mean values of features in today’s input (X):\")\n",
    "print(X.mean().sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d86330d-e8cd-434f-b44b-bfbbdd13bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Null counts in today_pred BEFORE fill:\n",
      "runs_allowed           13\n",
      "hits_allowed           13\n",
      "strikeouts_y           13\n",
      "walks_y                13\n",
      "hits                   13\n",
      "runs_1st               13\n",
      "total_bases            13\n",
      "pa                     13\n",
      "batters_faced          13\n",
      "strikeouts_x           13\n",
      "walks_x                13\n",
      "abs                    13\n",
      "game_pk_y              13\n",
      "runs_rolling10_team    13\n",
      "BB_rate_team           13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"🧪 Null counts in today_pred BEFORE fill:\")\n",
    "print(today_pred.isnull().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "901e3d03-63bd-4e56-b4d5-24d73de27c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Sample row from today_pred with key features:\n",
      "    pitcher  hits_allowed  ERA_season  WHIP_season  OBP_team  \\\n",
      "0  656550.0           NaN         NaN          NaN       NaN   \n",
      "1  680694.0           NaN         NaN          NaN       NaN   \n",
      "2  572070.0           NaN         NaN          NaN       NaN   \n",
      "3  669461.0           NaN        3.08         1.06       NaN   \n",
      "4  605135.0           NaN        3.80         1.36       NaN   \n",
      "\n",
      "   runs_rolling10_team  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"🧪 Sample row from today_pred with key features:\")\n",
    "print(today_pred[[\n",
    "    'pitcher', 'hits_allowed', 'ERA_season', 'WHIP_season', 'OBP_team', 'runs_rolling10_team'\n",
    "]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b918f812-d4f5-4be9-9f7c-6863807bbe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 Keys in today_pred (sample):\n",
      "    pitcher game_date_start                   team half_inning\n",
      "0  656550.0      2025-06-05   Arizona Diamondbacks     Top_1st\n",
      "1  680694.0      2025-06-05         Atlanta Braves     Bot_1st\n",
      "2  572070.0      2025-06-05     Kansas City Royals     Top_1st\n",
      "3  669461.0      2025-06-05     Kansas City Royals     Top_1st\n",
      "4  605135.0      2025-06-05  Philadelphia Phillies     Top_1st\n",
      "\n",
      "🎯 Keys in pitcher_form:\n",
      "   pitcher game_date_start\n",
      "0   425794      2023-05-06\n",
      "1   425794      2023-05-12\n",
      "2   425794      2023-05-18\n",
      "3   425794      2023-05-23\n",
      "4   425794      2023-05-29\n",
      "\n",
      "🏟️ Keys in team_offense:\n",
      "  team  game_date half_inning\n",
      "0  ATH 2025-03-15     Bot_1st\n",
      "1  ATH 2025-03-15     Top_1st\n",
      "2  ATH 2025-03-16     Top_1st\n",
      "3  ATH 2025-03-17     Bot_1st\n",
      "4  ATH 2025-03-19     Top_1st\n"
     ]
    }
   ],
   "source": [
    "print(\"👀 Keys in today_pred (sample):\")\n",
    "print(today_pred[['pitcher', 'game_date_start', 'team', 'half_inning']].head())\n",
    "\n",
    "print(\"\\n🎯 Keys in pitcher_form:\")\n",
    "print(pitcher_form[['pitcher', 'game_date_start']].drop_duplicates().head())\n",
    "\n",
    "print(\"\\n🏟️ Keys in team_offense:\")\n",
    "print(team_offense[['team', 'game_date', 'half_inning']].drop_duplicates().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd720f92-3598-407c-9b60-65d96797c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
